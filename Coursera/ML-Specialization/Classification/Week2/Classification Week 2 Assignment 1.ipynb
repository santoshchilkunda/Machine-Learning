{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to implement your own logistic regression classifier. You will:\n",
    "\n",
    "- Extract features from Amazon product reviews.\n",
    "- Convert an SFrame into a NumPy array.\n",
    "- Implement the link function for logistic regression.\n",
    "- Write a function to compute the derivative of the log likelihood function with respect to a single coefficient.\n",
    "- Implement gradient ascent.\n",
    "- Given a set of coefficients, predict sentiments.\n",
    "- Compute classification accuracy for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let us quickly explore more of this dataset. The name column indicates the name of the product. Try listing the name of the first 10 products in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumb...\n",
       "1      Nature's Lullabies Second Year Sticker Calendar\n",
       "2      Nature's Lullabies Second Year Sticker Calendar\n",
       "3                          Lamaze Peekaboo, I Love You\n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
       "5                            Our Baby Girl Memory Book\n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
       "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.name[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, try counting the number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive reviews: 26579\n",
      "num of negative reviews: 26493\n"
     ]
    }
   ],
   "source": [
    "print \"num of positive reviews:\", len(products[products.sentiment == 1])\n",
    "print \"num of negative reviews:\", len(products[products.sentiment == -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):    \n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''}) # needed to convert all reviews to strings\n",
    "products['review_clean'] = products.review.apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute word counts (only for important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('important_words.json') as data_file:    \n",
    "    important_words = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products.review_clean.apply(lambda r: r.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many reviews contain the word perfect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products[products.perfect > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data frame to multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['one'] = 1\n",
    "    features = ['one'] + features\n",
    "    features_array = dataframe[features].as_matrix()\n",
    "    output_label = dataframe[label].as_matrix()\n",
    "    \n",
    "    return (features_array, output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiments = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many features are there in the feature_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072L, 194L)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = 1 / (1 + np.exp(-score))\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_derivative(error, feature):\n",
    "    derivative = np.dot(feature, error)\n",
    "    return (derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiments, coefficients):\n",
    "    indicator = (sentiments == +1)\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    ll = np.sum((indicator - 1)*score - np.log(1 + np.exp(-score)))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix, sentiments, initial_coefficients, step_size, max_iter):\n",
    "    \n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    num_coeffs = len(coefficients)\n",
    "    \n",
    "    indicator = (sentiments == +1)\n",
    "\n",
    "    for i in xrange(max_iter):\n",
    "        predictions = predict_probability(feature_matrix, coefficients)        \n",
    "        error = (indicator - predictions)       \n",
    "        \n",
    "        for j in xrange(num_coeffs):\n",
    "            derivative = feature_derivative(error, feature_matrix[:,j])            \n",
    "            coefficients[j] = (coefficients[j] + step_size*derivative)            \n",
    "        \n",
    "        if (i%10 == 0):\n",
    "            ll = compute_log_likelihood(feature_matrix, sentiments, coefficients)\n",
    "            print i, ll\n",
    "    \n",
    "    return (coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us run the logistic regression solver with the parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_coeffs = np.zeros(np.size(feature_matrix, axis=1))\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As each iteration of gradient ascent passes, does the log likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -36780.9388104\n",
      "10 -36723.5732784\n",
      "20 -36666.7762571\n",
      "30 -36610.5346\n",
      "40 -36554.8360409\n",
      "50 -36499.6690994\n",
      "60 -36445.0229966\n",
      "70 -36390.8875808\n",
      "80 -36337.253263\n",
      "90 -36284.1109584\n",
      "100 -36231.4520359\n",
      "110 -36179.2682736\n",
      "120 -36127.5518186\n",
      "130 -36076.2951527\n",
      "140 -36025.4910611\n",
      "150 -35975.1326055\n",
      "160 -35925.2130998\n",
      "170 -35875.7260888\n",
      "180 -35826.6653291\n",
      "190 -35778.0247728\n",
      "200 -35729.7985518\n",
      "210 -35681.9809651\n",
      "220 -35634.5664668\n",
      "230 -35587.5496553\n",
      "240 -35540.925264\n",
      "250 -35494.6881529\n",
      "260 -35448.8333007\n",
      "270 -35403.3557983\n",
      "280 -35358.2508422\n",
      "290 -35313.5137295\n",
      "300 -35269.1398524\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiments, init_coeffs, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predicting_sentiment(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    sentiments = np.where(score > 0, 1, -1)\n",
    "    return (sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['pred_sentiments'] = predicting_sentiment(feature_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26147\n"
     ]
    }
   ],
   "source": [
    "positive_sentiments = len(products[products.pred_sentiments > 0])\n",
    "print positive_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39872\n"
     ]
    }
   ],
   "source": [
    "num_correctly_classified = len(products[products.sentiment == products.pred_sentiments])\n",
    "print num_correctly_classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751281278263\n"
     ]
    }
   ],
   "source": [
    "accuracy = (num_correctly_classified / len(products))\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which words contribute most to positive & negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_no_intercept = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coeff_no_intercept) for word, coeff_no_intercept in zip(important_words, coeff_no_intercept)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Which word is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'great', 0.066296001387255332),\n",
       " (u'love', 0.065724092902079465),\n",
       " (u'easy', 0.064614818395628382),\n",
       " (u'little', 0.045170071725352888),\n",
       " (u'loves', 0.044896490742526995),\n",
       " (u'well', 0.029938542166391018),\n",
       " (u'perfect', 0.029668947385268679),\n",
       " (u'old', 0.019844898517189645),\n",
       " (u'nice', 0.018310362000933323),\n",
       " (u'daughter', 0.01755742870228319)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which word is not present in the top 10 \"most negative\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'waste', -0.024082264094189641),\n",
       " (u'monitor', -0.024619007521754197),\n",
       " (u'return', -0.02664239217459799),\n",
       " (u'back', -0.027971174584613689),\n",
       " (u'disappointed', -0.02902990836552595),\n",
       " (u'get', -0.029045848805011123),\n",
       " (u'even', -0.030252629052075222),\n",
       " (u'work', -0.033213613120973838),\n",
       " (u'money', -0.039083643082457598),\n",
       " (u'product', -0.04175318698775627)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-11:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
