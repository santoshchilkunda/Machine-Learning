{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logistic Regression with L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to implement your own logistic regression classifier with L2 regularization. You will do the following:\n",
    "\n",
    "- Extract features from Amazon product reviews.\n",
    "- Convert an dataframe into a NumPy array.\n",
    "- Write a function to compute the derivative of log likelihood function with an L2 penalty with respect to a single coefficient.\n",
    "- Implement gradient ascent with an L2 penalty.\n",
    "- Empirically explore how the L2 penalty can ameliorate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and process review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})\n",
    "products['review_clean'] = products.review.apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('important_words.json') as data_file:\n",
    "    important_words = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products.review_clean.apply(lambda x: x.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('module-4-assignment-train-idx.json') as train_data_idx_file:\n",
    "    train_data_idx = json.load(train_data_idx_file)\n",
    "train_data = products.iloc[train_data_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('module-4-assignment-validation-idx.json') as validation_data_idx_file:\n",
    "    validation_data_idx = json.load(validation_data_idx_file)\n",
    "validation_data = products.iloc[validation_data_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data frame to multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, output):\n",
    "    dataframe['one'] = 1\n",
    "    features = ['one'] + features\n",
    "    feature_dataframe = dataframe[features]\n",
    "    feature_matrix = feature_dataframe.as_matrix()\n",
    "    \n",
    "    output_dataframe = dataframe[output]\n",
    "    output_matrix = output_dataframe.as_matrix()\n",
    "    \n",
    "    return (feature_matrix, output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Santosh\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building on logistic regression with no L2 penalty assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probability(features, coefficients):\n",
    "    score = np.dot(features, coefficients)\n",
    "    pred_prob = 1 / (1 + np.exp(-score))\n",
    "    return (pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(feature, error, coefficient, l2_penalty, is_coefficient_const):\n",
    "    derivative = np.dot(feature, error)\n",
    "    if not is_coefficient_const:\n",
    "        derivative = derivative - 2*l2_penalty*coefficient\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_l2(features, coefficients, sentiments, l2_penalty):\n",
    "    indicator = (sentiments == +1)\n",
    "    score = np.dot(features, coefficients)\n",
    "    coeff_excl_intercept = coefficients[1:]\n",
    "    norm2 = np.dot(coeff_excl_intercept, np.transpose(coeff_excl_intercept))\n",
    "    ll = np.sum((indicator - 1)*score - np.log(1+np.exp(-score))) - l2_penalty*norm2\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression_with_l2(feature_matrix, sentiments, initial_coefficients, l2_penalty, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    indicator = (sentiments == +1)\n",
    "    \n",
    "    for i in xrange(max_iter):\n",
    "        pred_prob = predict_probability(feature_matrix, coefficients)\n",
    "        error = (indicator - pred_prob)\n",
    "       \n",
    "        for j in xrange(len(coefficients)):\n",
    "            partial_derivative = feature_derivative(feature_matrix[:,j], error, coefficients[j], l2_penalty, (j == 0))\n",
    "            coefficients[j] = coefficients[j] + step_size*partial_derivative\n",
    "\n",
    "        \n",
    "    ll = compute_log_likelihood_with_l2(feature_matrix, coefficients, sentiments, l2_penalty)\n",
    "    print ll\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore effects of L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix_train\n",
    "sentiment = sentiment_train\n",
    "init_coeffs = np.zeros(np.size(feature_matrix, axis=1))\n",
    "step_size = 5e-6\n",
    "max_iter = 501\n",
    "l2_penalty_list = [0, 4, 10, 1e2, 1e3, 1e5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19877.0196926\n",
      "-19956.5011149\n",
      "-20072.5379352\n",
      "-21452.1576365\n",
      "-25532.6009112\n",
      "-29271.5217907\n"
     ]
    }
   ],
   "source": [
    "coefficients_with_l2 = np.zeros([len(l2_penalty_list), 194])\n",
    "for i in xrange(len(l2_penalty_list)):\n",
    "    coefficients_with_l2[i] = logistic_regression_with_l2(feature_matrix, sentiment, init_coeffs, l2_penalty_list[i], step_size, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients_0_penalty = coefficients_with_l2[0]\n",
    "coeff_0_no_intercept = list(coefficients_0_penalty[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coeff_0_no_intercept) for word, coeff_0_no_intercept in zip(important_words, coeff_0_no_intercept)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Question. Which of the following is not listed in either positive_words or negative_words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'love', 1.0596997836496707),\n",
       " (u'loves', 1.0534098221067272),\n",
       " (u'easy', 0.98509587876641302),\n",
       " (u'perfect', 0.8365276388026418),\n",
       " (u'great', 0.80232122759453262)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'broke', -0.55466734803725326),\n",
       " (u'returned', -0.57227874791041922),\n",
       " (u'waste', -0.61733291621555997),\n",
       " (u'return', -0.74162459742417763),\n",
       " (u'money', -0.76797407462045209)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       -inf  0.60205999  1.          2.          3.          5.        ]\n"
     ]
    }
   ],
   "source": [
    "x_axis = np.log10(l2_penalty_list)\n",
    "print x_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_idx(str, important_words):\n",
    "    i = 0\n",
    "    for word in important_words:\n",
    "        if(word == str):\n",
    "            break\n",
    "        i = i+1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coeff_list(coefficients_k_penalty, word_list, important_words):\n",
    "    coeff_list = np.zeros(len(word_list))\n",
    "    i = 0\n",
    "    for word in word_list:\n",
    "        idx = (find_idx(word, important_words) + 1)\n",
    "        coeff_list[i] = coefficients_k_penalty[idx]\n",
    "        i = i + 1\n",
    "    return coeff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_list = np.reshape(([[coeff_tuple_0[0:5,0], coeff_tuple_0[-6:-1,0]]]), [10,1])\n",
    "word_list = ['love', 'easy', 'loves', 'great', 'perfect', 'returned', 'work', 'waste', 'return', 'money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_axis = np.zeros([len(l2_penalty_list) ,10])\n",
    "for i in xrange(len(l2_penalty_list)):\n",
    "    y_axis[i] = get_coeff_list(coefficients_with_l2[i], word_list, important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xcc07d30>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFwCAYAAAD9idyvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf96358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "cmap_positive = plt.get_cmap('Reds')\n",
    "cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "xx = x_axis\n",
    "plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predicting_sentiment(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = np.where(score > 0, 1, -1)\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(products, feature_matrix, coeffs, sentiments):\n",
    "    predictions = predicting_sentiment(feature_matrix, coeffs)\n",
    "    num_correctly_classified = np.sum(predictions == sentiments)\n",
    "    accuracy = (num_correctly_classified / len(products))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which of the following models has the highest accuracy on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785203371025\n",
      "0.785132551167\n",
      "0.785061731309\n",
      "0.783857793725\n",
      "0.774108259956\n",
      "0.683057529331\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(l2_penalty_list)):\n",
    "    print calc_accuracy(train_data, feature_matrix_train, coefficients_with_l2[i], sentiment_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which of the following models has the highest accuracy on the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781813089347\n",
      "0.781813089347\n",
      "0.781626365419\n",
      "0.78143964149\n",
      "0.770703015591\n",
      "0.670712351788\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(l2_penalty_list)):\n",
    "    print calc_accuracy(validation_data, feature_matrix_valid, coefficients_with_l2[i], sentiment_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
